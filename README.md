# Content PDF Creator

[![License: ISC](https://img.shields.io/badge/License-ISC-blue.svg)](https://opensource.org/licenses/ISC)
[![Node.js](https://img.shields.io/badge/node-%3E%3D18.0.0-brightgreen.svg)](https://nodejs.org/)

A Node.js tool that scrapes website content and generates clean, well-formatted PDF documents. Built with Cheerio for HTML parsing and Puppeteer for PDF generation.

## Features

- 🌐 Scrapes dynamic websites with JavaScript support
- 📄 Generates professional PDF documents
- 🧹 Intelligent content extraction (removes navigation, ads, duplicates)
- 🎨 Clean, readable formatting
- 📊 Preserves headings, paragraphs, lists, and quotes
- 🔄 Removes duplicate content automatically
- ⚡ Lightweight and fast

## Installation

```bash
# Install dependencies
yarn install
# or
npm install
```

## Dependencies

- **axios** - HTTP client for fetching HTML
- **cheerio** - HTML parsing and manipulation
- **puppeteer** - PDF generation

## Usage

### Basic Usage

```javascript
import { generatePDF } from './contentPdfCreator.js';

// Generate PDF from URL
await generatePDF('https://example.com', './output.pdf');
```

### With Custom Options

```javascript
await generatePDF('https://example.com', './output.pdf', {
  format: 'A4',
  margin: {
    top: '15mm',
    right: '15mm',
    bottom: '15mm',
    left: '15mm'
  },
  footerText: 'Generated by My Company' // Custom footer text
});
```

### Advanced Usage

```javascript
import { scrapeContent, generateHTML, createPDFFromHTML } from './contentPdfCreator.js';

// Step-by-step pipeline
const content = await scrapeContent('https://example.com');
const html = generateHTML(content);
await createPDFFromHTML(html, './output.pdf');
```

### Running the Example

```bash
# Run with default example
node contentPdfCreator.js

# Or modify the URL in the file
yarn start
```

## How It Works

### 1. Content Extraction

The scraper extracts:
- **Headings** (h1-h6)
- **Paragraphs** (with min. 3 characters)
- **Lists** (bullet and numbered)
- **Blockquotes**

### 2. Content Cleaning

Automatically removes:
- Scripts, styles, and SVGs
- Navigation menus and headers/footers
- Forms and input elements
- Buttons and interactive elements
- Duplicate content

### 3. PDF Generation

- Professional typography
- Proper page breaks
- Metadata (source URL, generation date)
- German locale formatting

## Configuration

### Minimum Text Length

Adjust the minimum text length for paragraphs:

```javascript
const isValidText = (text, minLength = 3) =>
  text && text.trim().length >= minLength;
```

### Content Selectors

Customize which elements to extract:

```javascript
const mainContent = $('main, .main-content, #main, article, [role="main"], body').first();
```

### Removal Rules

Add custom removal rules:

```javascript
const removeUnwantedElements = ($) => {
  $('script, style, noscript, iframe, svg').remove();
  $('header, footer, nav').remove();
  // Add your custom rules here
  $('.custom-class-to-remove').remove();
  return $;
};
```

## API Reference

### `generatePDF(url, outputPath, options)`

Generates a PDF from a URL.

**Parameters:**
- `url` (string) - Website URL to scrape
- `outputPath` (string) - Output PDF file path
- `options` (object) - PDF options
  - `format` (string) - Page format (default: 'A4')
  - `margin` (object) - Page margins
  - `footerText` (string) - Custom footer text (default: 'Dokument aus Shopify Store Content generiert')

**Returns:** Promise<object> - Scraped content object

### `scrapeContent(url)`

Scrapes content from a URL.

**Returns:** Promise<object>
```javascript
{
  title: string,
  metadata: { description, url, scrapedAt },
  sections: Array<{type, content, items}>
}
```

### `generateHTML(content, options)`

Generates HTML from scraped content.

**Parameters:**
- `content` (object) - Content object from `scrapeContent()`
- `options` (object) - HTML options
  - `footerText` (string) - Custom footer text

**Returns:** string - HTML document

### `createPDFFromHTML(html, outputPath, options)`

Creates a PDF from HTML.

**Parameters:**
- `html` (string) - HTML content
- `outputPath` (string) - Output file path
- `options` (object) - PDF options

## Examples

### Scrape Product Page

```javascript
await generatePDF(
  'https://example.com/products/item',
  './product.pdf'
);
```

### Scrape Blog Article

```javascript
await generatePDF(
  'https://blog.example.com/article',
  './article.pdf',
  {
    format: 'Letter',
    footerText: 'Copyright © 2025 My Blog'
  }
);
```

### Custom Pipeline

```javascript
const content = await scrapeContent('https://example.com');

// Modify content before PDF generation
content.sections = content.sections.filter(s => s.type !== 'quote');

const html = generateHTML(content);
await createPDFFromHTML(html, './custom.pdf');
```

## Troubleshooting

### Missing Content

If content is missing from the PDF:

1. Check if text meets minimum length (default: 3 characters)
2. Verify the element isn't being removed by cleaning rules
3. Check if content is inside a removed parent element

### Duplicate Content

The scraper automatically deduplicates content based on type and text. If you see duplicates:

1. Check if content differs slightly (whitespace, formatting)
2. Adjust the deduplication logic in `extractSections()`

### Formatting Issues

- Inline formatting (bold, italic, links) is not preserved - only plain text
- To preserve formatting, modify extraction to use `.html()` instead of `.text()`

## Project Structure

```
fetch/
├── contentPdfCreator.js    # Main scraper and PDF generator
├── fetchSite.js           # Alternative Playwright-based scraper
├── package.json           # Dependencies and scripts
├── output.pdf            # Generated PDF (example)
└── README.md             # This file
```

## License

This project is licensed under the ISC License - see the [LICENSE](LICENSE) file for details.

### Third-Party Licenses

This project uses third-party libraries that are licensed under their own terms:
- axios (MIT)
- cheerio (MIT)
- puppeteer (Apache 2.0)

## Author

**MOGHANCY**

## Contributing

Contributions are welcome! Feel free to:
- Report bugs by opening an issue
- Suggest new features
- Submit pull requests

Please follow the [Conventional Commits](https://www.conventionalcommits.org/) standard for commit messages.
